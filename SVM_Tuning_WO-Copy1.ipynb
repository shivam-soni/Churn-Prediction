{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'std = StandardScaler().fit(X[num_cols])\\nx_transformed=std.transform(X[num_cols])\\nx_transformed_df=pd.DataFrame(x_transformed,columns=num_cols)\\nx_kf=X.drop(num_cols,1)\\nx_kf=pd.concat([x_kf.reset_index(drop=True),x_transformed_df.reset_index(drop=True) ],axis=1)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pt\n",
    "import pandas as pd\n",
    "import statsmodels.stats.outliers_influence as oi\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "df=pd.read_csv('Churn.csv')\n",
    "\n",
    "\"\"\"----------------------------DATA PREPARATION--------------------------\"\"\"\n",
    "\n",
    "for i in df.columns:\n",
    "    df[i]=df[i].replace(\" \",np.NaN)\n",
    "    \n",
    "#print (df.isnull().sum())\n",
    "\n",
    "    \n",
    "df.dropna(inplace=True)\n",
    "df = df.reset_index()[df.columns]\n",
    "#print (df.isnull().sum())\n",
    "'''def tenure_lab(t) :\n",
    "    \n",
    "    if t <= 12 :\n",
    "        return 1\n",
    "    elif (t > 12) & (t <= 24 ):\n",
    "        return 2\n",
    "    elif (t > 24) & (t <= 48) :\n",
    "        return 3\n",
    "    elif (t > 48) & (t <= 60) :\n",
    "        return 4\n",
    "    elif t > 60 :\n",
    "        return 5\n",
    "\n",
    "df[\"tenure\"]=df[\"tenure\"].map(tenure_lab)'''\n",
    "\n",
    "\n",
    "#since we have 72 categories in tenure we will reduce the number of categories in it\n",
    "#therefoe we made above function and to check how many categories each column has now,we are using the following loop\n",
    "\n",
    "for c_n in df.columns:\n",
    "    #print c_n\n",
    "   # if X[c_n]=='object' :\n",
    "    unique_cat=df[c_n].nunique()\n",
    "    #print (\"Feature\", c_n,\"has\", unique_cat,\"unique categories\")\n",
    "\n",
    "\n",
    "X=df.drop('Churn',1)\n",
    "Y=df.Churn\n",
    "\n",
    "X=X.drop('customerID',1)\n",
    "\n",
    "todummy_list  =X.nunique()[X.nunique() < 6].keys().tolist()\n",
    "\n",
    "num_cols   = [x for x in X.columns if x not in todummy_list]\n",
    "'''todummy_list.remove('tenure')\n",
    "num_cols.insert(3,'tenure')'''\n",
    "X_org=X.copy()\n",
    "\n",
    "for i in todummy_list:\n",
    "    dummies= pd.get_dummies(X[i],prefix=i)\n",
    "    #print dummies\n",
    "    #dummies=dummies.iloc[:,1:]\n",
    "    X=X.drop(i,1)\n",
    "    X=pd.concat([dummies,X],axis=1)\n",
    "X=X.drop(['StreamingTV_No internet service','StreamingMovies_No internet service','TechSupport_No internet service','DeviceProtection_No internet service','OnlineBackup_No internet service'],axis=1)\n",
    "    \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "le = LabelEncoder()\n",
    "Y= le.fit_transform(Y)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=0)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Fitting parameters for scaling x_train for the numerical columns \n",
    "std = StandardScaler().fit(x_train[num_cols])\n",
    "#Transforming the the original data\n",
    "x_train_transformed=std.transform(x_train[num_cols])\n",
    "x_train_transformed_df = pd.DataFrame(x_train_transformed,columns=num_cols)\n",
    "x_train=x_train.drop(num_cols,1)\n",
    "x_train=pd.concat([x_train.reset_index(drop=True),x_train_transformed_df.reset_index(drop=True) ],axis=1)\n",
    "\n",
    "#Transforming the the test data's numerical with x_train scaled parameters\n",
    "x_test_transformed=std.transform(x_test[num_cols])\n",
    "x_test_transformed_df = pd.DataFrame(x_test_transformed,columns=num_cols)\n",
    "x_test=x_test.drop(num_cols,1)\n",
    "x_test=pd.concat([x_test.reset_index(drop=True),x_test_transformed_df .reset_index(drop=True) ],axis=1)\n",
    "\n",
    "'''std = StandardScaler().fit(X[num_cols])\n",
    "x_transformed=std.transform(X[num_cols])\n",
    "x_transformed_df=pd.DataFrame(x_transformed,columns=num_cols)\n",
    "x_kf=X.drop(num_cols,1)\n",
    "x_kf=pd.concat([x_kf.reset_index(drop=True),x_transformed_df.reset_index(drop=True) ],axis=1)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tenure', 'MonthlyCharges', 'TotalCharges']\n",
      "['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5625, 41)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(num_cols)\n",
    "print(todummy_list)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_plot(clf_obj,x_test,y_test,predictions):\n",
    "    \n",
    "    # all parameters not specified are set to their defaults\n",
    "    \n",
    "   \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    " \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, predictions)\n",
    "    \n",
    "    print(\"tpr=\",tpr,\" and 1-fpr=\", 1-fpr)\n",
    "\n",
    "    #plot no skill\n",
    "    from matplotlib import pyplot\n",
    "    pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "    # plot the roc curve for the model\n",
    "    pyplot.plot(fpr, tpr, marker='.')\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "\n",
    "    auc = roc_auc_score(y_test, predictions)\n",
    "    print('AUC: %.3f' % auc)\n",
    "    '''probs = m.predict_proba(x_test)\n",
    "    probs = probs[:, 1]\n",
    "\n",
    "\n",
    "    fpr1, tpr1, thresholds1 = roc_curve(y_test, probs)\n",
    "\n",
    "    #plot no skill\n",
    "    pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "    # plot the roc curve for the model\n",
    "    pyplot.plot(fpr1, tpr1, marker='.')\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    "\n",
    "    auc = roc_auc_score(y_test, probs)\n",
    "    print('AUC: %.3f' % auc)'''\n",
    "\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    score = clf_obj.score(x_test, y_test)\n",
    "    plt.figure(figsize=(9,9))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "    plt.ylabel('Actual label');\n",
    "    plt.xlabel('Predicted label');\n",
    "    all_sample_title =' Accuracy Score: {0}'.format(score)\n",
    "    plt.title(all_sample_title, size = 15);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'C': array([1., 2., 3., 4.]), 'gamma': [0.03, 0.02, 0.01]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "SVM=SVC(probability=False)\n",
    "\n",
    "gs = GridSearchCV(SVM, param_grid={'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],'C': 0.0 ++ np.arange(1, 5),'gamma':[0.03,0.02,0.01]},scoring='roc_auc')\n",
    "gs.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) 0.836 (+/-0.021) for {'C': 1.0, 'gamma': 0.03, 'kernel': 'linear'}\n",
      "2) 0.810 (+/-0.024) for {'C': 1.0, 'gamma': 0.03, 'kernel': 'poly'}\n",
      "3) 0.820 (+/-0.022) for {'C': 1.0, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "4) 0.822 (+/-0.027) for {'C': 1.0, 'gamma': 0.03, 'kernel': 'sigmoid'}\n",
      "5) 0.836 (+/-0.021) for {'C': 1.0, 'gamma': 0.02, 'kernel': 'linear'}\n",
      "6) 0.817 (+/-0.023) for {'C': 1.0, 'gamma': 0.02, 'kernel': 'poly'}\n",
      "7) 0.826 (+/-0.020) for {'C': 1.0, 'gamma': 0.02, 'kernel': 'rbf'}\n",
      "8) 0.835 (+/-0.023) for {'C': 1.0, 'gamma': 0.02, 'kernel': 'sigmoid'}\n",
      "9) 0.836 (+/-0.021) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "10) 0.820 (+/-0.022) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "11) 0.838 (+/-0.021) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "12) 0.838 (+/-0.021) for {'C': 1.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "13) 0.836 (+/-0.021) for {'C': 2.0, 'gamma': 0.03, 'kernel': 'linear'}\n",
      "14) 0.806 (+/-0.024) for {'C': 2.0, 'gamma': 0.03, 'kernel': 'poly'}\n",
      "15) 0.815 (+/-0.022) for {'C': 2.0, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "16) 0.783 (+/-0.020) for {'C': 2.0, 'gamma': 0.03, 'kernel': 'sigmoid'}\n",
      "17) 0.836 (+/-0.021) for {'C': 2.0, 'gamma': 0.02, 'kernel': 'linear'}\n",
      "18) 0.814 (+/-0.025) for {'C': 2.0, 'gamma': 0.02, 'kernel': 'poly'}\n",
      "19) 0.821 (+/-0.023) for {'C': 2.0, 'gamma': 0.02, 'kernel': 'rbf'}\n",
      "20) 0.832 (+/-0.025) for {'C': 2.0, 'gamma': 0.02, 'kernel': 'sigmoid'}\n",
      "21) 0.836 (+/-0.021) for {'C': 2.0, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "22) 0.820 (+/-0.022) for {'C': 2.0, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "23) 0.834 (+/-0.022) for {'C': 2.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "24) 0.837 (+/-0.022) for {'C': 2.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "25) 0.836 (+/-0.022) for {'C': 3.0, 'gamma': 0.03, 'kernel': 'linear'}\n",
      "26) 0.804 (+/-0.025) for {'C': 3.0, 'gamma': 0.03, 'kernel': 'poly'}\n",
      "27) 0.811 (+/-0.022) for {'C': 3.0, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "28) 0.773 (+/-0.044) for {'C': 3.0, 'gamma': 0.03, 'kernel': 'sigmoid'}\n",
      "29) 0.836 (+/-0.022) for {'C': 3.0, 'gamma': 0.02, 'kernel': 'linear'}\n",
      "30) 0.811 (+/-0.024) for {'C': 3.0, 'gamma': 0.02, 'kernel': 'poly'}\n",
      "31) 0.819 (+/-0.021) for {'C': 3.0, 'gamma': 0.02, 'kernel': 'rbf'}\n",
      "32) 0.826 (+/-0.025) for {'C': 3.0, 'gamma': 0.02, 'kernel': 'sigmoid'}\n",
      "33) 0.836 (+/-0.022) for {'C': 3.0, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "34) 0.820 (+/-0.022) for {'C': 3.0, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "35) 0.828 (+/-0.019) for {'C': 3.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "36) 0.837 (+/-0.022) for {'C': 3.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "37) 0.836 (+/-0.022) for {'C': 4.0, 'gamma': 0.03, 'kernel': 'linear'}\n",
      "38) 0.803 (+/-0.025) for {'C': 4.0, 'gamma': 0.03, 'kernel': 'poly'}\n",
      "39) 0.809 (+/-0.020) for {'C': 4.0, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "40) 0.780 (+/-0.019) for {'C': 4.0, 'gamma': 0.03, 'kernel': 'sigmoid'}\n",
      "41) 0.836 (+/-0.022) for {'C': 4.0, 'gamma': 0.02, 'kernel': 'linear'}\n",
      "42) 0.809 (+/-0.024) for {'C': 4.0, 'gamma': 0.02, 'kernel': 'poly'}\n",
      "43) 0.817 (+/-0.021) for {'C': 4.0, 'gamma': 0.02, 'kernel': 'rbf'}\n",
      "44) 0.820 (+/-0.024) for {'C': 4.0, 'gamma': 0.02, 'kernel': 'sigmoid'}\n",
      "45) 0.836 (+/-0.022) for {'C': 4.0, 'gamma': 0.01, 'kernel': 'linear'}\n",
      "46) 0.819 (+/-0.022) for {'C': 4.0, 'gamma': 0.01, 'kernel': 'poly'}\n",
      "47) 0.826 (+/-0.021) for {'C': 4.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "48) 0.836 (+/-0.022) for {'C': 4.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "Best score: 0.8380\n",
      "Best parameters:\n",
      " {'C': 1.0, 'gamma': 0.01, 'kernel': 'sigmoid'}\n",
      "Best estimator:\n",
      " SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "means = gs.cv_results_['mean_test_score']\n",
    "stds = gs.cv_results_['std_test_score']\n",
    "c=0\n",
    "for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "    c=c+1\n",
    "    print(\"%d) %0.3f (+/-%0.03f) for %r\"% (c,mean, std * 2, params))\n",
    "\n",
    "print(\"Best score: %0.4f\" % gs.best_score_)\n",
    "\n",
    "print(\"Best parameters:\\n\",gs.best_params_)\n",
    "\n",
    "\n",
    "print(\"Best estimator:\\n\",gs.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=-1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='sigmoid',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "#m=gs.best_estimator_\n",
    "m=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='sigmoid',\n",
    "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "print (m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "C <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c8cd72a7a526>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmett\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmett\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    269\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\svm\\libsvm.pyx\u001b[0m in \u001b[0;36msklearn.svm.libsvm.fit\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: C <= 0"
     ]
    }
   ],
   "source": [
    "model=m.fit(x_train, y_train)\n",
    "predictions = model.predict(x_test)\n",
    "from sklearn import metrics\n",
    "mett=metrics.classification_report(y_test,predictions)\n",
    "print (mett)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, predictions)\n",
    "print(cm)\n",
    "\n",
    "\n",
    "roc_plot(m,x_test,y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
